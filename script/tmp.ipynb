{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import ipywidgets as widgets \r\n",
    "import numpy as np\r\n",
    "import json\r\n",
    "from tqdm.auto import tqdm\r\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath='data/'\r\n",
    "df_names=['players','seasons','teams','awards','train']\r\n",
    "for name in df_names:\r\n",
    "    globals()[name]=pd.read_csv(f'{basepath}{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358bbdbcfbe04d359d1127fea8eaa204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output()), _titles={'0': 'players', '1': 'seasons', '2':â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datatabs=widgets.Tab()\r\n",
    "datatabs.children = list([widgets.Output() for df_name in df_names])\r\n",
    "\r\n",
    "for index in range(0, len(df_names)):\r\n",
    "    # Rename tab bar titles to df names\r\n",
    "    datatabs.set_title(index, df_names[index])\r\n",
    "    \r\n",
    "    # Display corresponding table output for this tab name\r\n",
    "    with datatabs.children[index]:\r\n",
    "        display(eval(df_names[index]).head())\r\n",
    "\r\n",
    "display(datatabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=datetime64[ns] and ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_validate_comparison_value\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_object\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_validate_listlike\u001b[1;34m(self, value, opname, cast_str, allow_object)\u001b[0m\n\u001b[0;32m    851\u001b[0m             raise TypeError(\n\u001b[1;32m--> 852\u001b[1;33m                 \u001b[1;34mf\"{opname} requires compatible dtype or scalar, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m                 \u001b[1;34mf\"not {type(value).__name__}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __ge__ requires compatible dtype or scalar, not StringArray",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidComparison\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_comparison_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidComparison\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_validate_comparison_value\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mInvalidComparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidComparison\u001b[0m: ['2018-03-29' '2018-03-29' '2018-03-29' ... '2021-04-01' '2021-04-01'\n '2021-04-01']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e3a36262f37c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mdates_with_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'regularSeasonStartDate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mdates_with_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'postSeasonEndDate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0minclusive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     )\n\u001b[0;32m     66\u001b[0m   )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mbetween\u001b[1;34m(self, left, right, inclusive)\u001b[0m\n\u001b[0;32m   4768\u001b[0m         \"\"\"\n\u001b[0;32m   4769\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minclusive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4770\u001b[1;33m             \u001b[0mlmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4771\u001b[0m             \u001b[0mrmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4772\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_extension_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# Call the method on lvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_comparison_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidComparison\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minvalid_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\ops\\invalid.py\u001b[0m in \u001b[0;36minvalid_comparison\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid comparison between dtype={left.dtype} and {typ}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid comparison between dtype=datetime64[ns] and ndarray"
     ]
    }
   ],
   "source": [
    "# Helper function to unpack json found in daily data\r\n",
    "def unpack_json(json_str):\r\n",
    "    return np.nan if pd.isna(json_str) else pd.read_json(json_str)\r\n",
    "\r\n",
    "#### Unnest various nested data within training (daily) data ####\r\n",
    "daily_data_unnested_dfs = pd.DataFrame(data = {\r\n",
    "  'dfName': train.drop('date', axis = 1).columns.values.tolist()\r\n",
    "  })\r\n",
    "\r\n",
    "daily_data_unnested_dfs['df'] = [pd.DataFrame() for row in \r\n",
    "  daily_data_unnested_dfs.iterrows()]\r\n",
    "\r\n",
    "for df_index, df_row in daily_data_unnested_dfs.iterrows():\r\n",
    "    nestedTableName = str(df_row['dfName'])\r\n",
    "    \r\n",
    "    date_nested_table = train[['date', nestedTableName]]\r\n",
    "    \r\n",
    "    date_nested_table = (date_nested_table[\r\n",
    "      ~pd.isna(date_nested_table[nestedTableName])\r\n",
    "      ].\r\n",
    "      reset_index(drop = True)\r\n",
    "      )\r\n",
    "    \r\n",
    "    daily_dfs_collection = []\r\n",
    "    \r\n",
    "    for date_index, date_row in date_nested_table.iterrows():\r\n",
    "        daily_df = unpack_json(date_row[nestedTableName])\r\n",
    "        \r\n",
    "        daily_df['dailyDataDate'] = date_row['date']\r\n",
    "        \r\n",
    "        daily_dfs_collection = daily_dfs_collection + [daily_df]\r\n",
    "\r\n",
    "    unnested_table = pd.concat(daily_dfs_collection,\r\n",
    "      ignore_index = True).set_index('dailyDataDate').reset_index()\r\n",
    "\r\n",
    "    # Creates 1 pandas df per unnested df from daily data read in, with same name\r\n",
    "    globals()[df_row['dfName']] = unnested_table    \r\n",
    "    \r\n",
    "    daily_data_unnested_dfs['df'][df_index] = unnested_table\r\n",
    "\r\n",
    "del train\r\n",
    "gc.collect()\r\n",
    "\r\n",
    "#### Get some information on each date in daily data (using season dates of interest) ####\r\n",
    "dates = pd.DataFrame(data = \r\n",
    "  {'dailyDataDate': nextDayPlayerEngagement['dailyDataDate'].unique()})\r\n",
    "\r\n",
    "dates['date'] = pd.to_datetime(dates['dailyDataDate'].astype(str))\r\n",
    "\r\n",
    "dates['year'] = dates['date'].dt.year\r\n",
    "dates['month'] = dates['date'].dt.month\r\n",
    "\r\n",
    "dates_with_info = pd.merge(\r\n",
    "  dates,\r\n",
    "  seasons,\r\n",
    "  left_on = 'year',\r\n",
    "  right_on = 'seasonId'\r\n",
    "  )\r\n",
    "\r\n",
    "dates_with_info['inSeason'] = (\r\n",
    "  dates_with_info['date'].between(\r\n",
    "    dates_with_info['regularSeasonStartDate'],\r\n",
    "    dates_with_info['postSeasonEndDate'],\r\n",
    "    inclusive = True\r\n",
    "    )\r\n",
    "  )\r\n",
    "\r\n",
    "dates_with_info['seasonPart'] = np.select(\r\n",
    "  [\r\n",
    "    dates_with_info['date'] < dates_with_info['preSeasonStartDate'], \r\n",
    "    dates_with_info['date'] < dates_with_info['regularSeasonStartDate'],\r\n",
    "    dates_with_info['date'] <= dates_with_info['lastDate1stHalf'],\r\n",
    "    dates_with_info['date'] < dates_with_info['firstDate2ndHalf'],\r\n",
    "    dates_with_info['date'] <= dates_with_info['regularSeasonEndDate'],\r\n",
    "    dates_with_info['date'] < dates_with_info['postSeasonStartDate'],\r\n",
    "    dates_with_info['date'] <= dates_with_info['postSeasonEndDate'],\r\n",
    "    dates_with_info['date'] > dates_with_info['postSeasonEndDate']\r\n",
    "  ], \r\n",
    "  [\r\n",
    "    'Offseason',\r\n",
    "    'Preseason',\r\n",
    "    'Reg Season 1st Half',\r\n",
    "    'All-Star Break',\r\n",
    "    'Reg Season 2nd Half',\r\n",
    "    'Between Reg and Postseason',\r\n",
    "    'Postseason',\r\n",
    "    'Offseason'\r\n",
    "  ], \r\n",
    "  default = np.nan\r\n",
    "  )\r\n",
    "\r\n",
    "#### Add some pitching stats/pieces of info to player game level stats ####\r\n",
    "\r\n",
    "player_game_stats = (playerBoxScores.copy().\r\n",
    "  # Change team Id/name to reflect these come from player game, not roster\r\n",
    "  rename(columns = {'teamId': 'gameTeamId', 'teamName': 'gameTeamName'})\r\n",
    "  )\r\n",
    "\r\n",
    "# Adds in field for innings pitched as fraction (better for aggregation)\r\n",
    "player_game_stats['inningsPitchedAsFrac'] = np.where(\r\n",
    "  pd.isna(player_game_stats['inningsPitched']),\r\n",
    "  np.nan,\r\n",
    "  np.floor(player_game_stats['inningsPitched']) +\r\n",
    "    (player_game_stats['inningsPitched'] -\r\n",
    "      np.floor(player_game_stats['inningsPitched'])) * 10/3\r\n",
    "  )\r\n",
    "\r\n",
    "# Add in Tom Tango pitching game score (https://www.mlb.com/glossary/advanced-stats/game-score)\r\n",
    "player_game_stats['pitchingGameScore'] = (40\r\n",
    "#     + 2 * player_game_stats['outs']\r\n",
    "    + 1 * player_game_stats['strikeOutsPitching']\r\n",
    "    - 2 * player_game_stats['baseOnBallsPitching']\r\n",
    "    - 2 * player_game_stats['hitsPitching']\r\n",
    "    - 3 * player_game_stats['runsPitching']\r\n",
    "    - 6 * player_game_stats['homeRunsPitching']\r\n",
    "    )\r\n",
    "\r\n",
    "# Add in criteria for no-hitter by pitcher (individual, not multiple pitchers)\r\n",
    "player_game_stats['noHitter'] = np.where(\r\n",
    "  (player_game_stats['gamesStartedPitching'] == 1) &\r\n",
    "  (player_game_stats['inningsPitched'] >= 9) &\r\n",
    "  (player_game_stats['hitsPitching'] == 0),\r\n",
    "  1, 0\r\n",
    "  )\r\n",
    "\r\n",
    "player_date_stats_agg = pd.merge(\r\n",
    "  (player_game_stats.\r\n",
    "    groupby(['dailyDataDate', 'playerId'], as_index = False).\r\n",
    "    # Some aggregations that are not simple sums\r\n",
    "    agg(\r\n",
    "      numGames = ('gamePk', 'nunique'),\r\n",
    "      # Should be 1 team per player per day, but adding here for 1 exception:\r\n",
    "      # playerId 518617 (Jake Diekman) had 2 games for different teams marked\r\n",
    "      # as played on 5/19/19, due to resumption of game after he was traded\r\n",
    "      numTeams = ('gameTeamId', 'nunique'),\r\n",
    "      # Should be only 1 team for almost all player-dates, taking min to simplify\r\n",
    "      gameTeamId = ('gameTeamId', 'min')\r\n",
    "      )\r\n",
    "    ),\r\n",
    "  # Merge with a bunch of player stats that can be summed at date/player level\r\n",
    "  (player_game_stats.\r\n",
    "    groupby(['dailyDataDate', 'playerId'], as_index = False)\r\n",
    "    [['runsScored', 'homeRuns', 'strikeOuts', 'baseOnBalls', 'hits',\r\n",
    "      'hitByPitch', 'atBats', 'caughtStealing', 'stolenBases',\r\n",
    "      'groundIntoDoublePlay', 'groundIntoTriplePlay', 'plateAppearances',\r\n",
    "      'totalBases', 'rbi', 'leftOnBase', 'sacBunts', 'sacFlies',\r\n",
    "      'gamesStartedPitching', 'runsPitching', 'homeRunsPitching', \r\n",
    "      'strikeOutsPitching', 'baseOnBallsPitching', 'hitsPitching',\r\n",
    "      'inningsPitchedAsFrac', 'earnedRuns', \r\n",
    "      'battersFaced','saves', 'blownSaves', 'pitchingGameScore', \r\n",
    "      'noHitter'\r\n",
    "      ]].\r\n",
    "    sum()\r\n",
    "    ),\r\n",
    "  on = ['dailyDataDate', 'playerId'],\r\n",
    "  how = 'inner'\r\n",
    "  )\r\n",
    "\r\n",
    "#### Turn games table into 1 row per team-game, then merge with team box scores ####\r\n",
    "# Filter to regular or Postseason games w/ valid scores for this part\r\n",
    "games_for_stats = games[\r\n",
    "  np.isin(games['gameType'], ['R', 'F', 'D', 'L', 'W', 'C', 'P']) &\r\n",
    "  ~pd.isna(games['homeScore']) &\r\n",
    "  ~pd.isna(games['awayScore'])\r\n",
    "  ]\r\n",
    "\r\n",
    "# Get games table from home team perspective\r\n",
    "games_home_perspective = games_for_stats.copy()\r\n",
    "\r\n",
    "# Change column names so that \"team\" is \"home\", \"opp\" is \"away\"\r\n",
    "games_home_perspective.columns = [\r\n",
    "  col_value.replace('home', 'team').replace('away', 'opp') for \r\n",
    "    col_value in games_home_perspective.columns.values]\r\n",
    "\r\n",
    "games_home_perspective['isHomeTeam'] = 1\r\n",
    "\r\n",
    "# Get games table from away team perspective\r\n",
    "games_away_perspective = games_for_stats.copy()\r\n",
    "\r\n",
    "# Change column names so that \"opp\" is \"home\", \"team\" is \"away\"\r\n",
    "games_away_perspective.columns = [\r\n",
    "  col_value.replace('home', 'opp').replace('away', 'team') for \r\n",
    "    col_value in games_away_perspective.columns.values]\r\n",
    "\r\n",
    "games_away_perspective['isHomeTeam'] = 0\r\n",
    "\r\n",
    "# Put together games from home/away perspective to get df w/ 1 row per team game\r\n",
    "team_games = (pd.concat([\r\n",
    "  games_home_perspective,\r\n",
    "  games_away_perspective\r\n",
    "  ],\r\n",
    "  ignore_index = True)\r\n",
    "  )\r\n",
    "\r\n",
    "# Copy over team box scores data to modify\r\n",
    "team_game_stats = teamBoxScores.copy()\r\n",
    "\r\n",
    "# Change column names to reflect these are all \"team\" stats - helps \r\n",
    "# to differentiate from individual player stats if/when joining later\r\n",
    "team_game_stats.columns = [\r\n",
    "  (col_value + 'Team') \r\n",
    "  if (col_value not in ['dailyDataDate', 'home', 'teamId', 'gamePk',\r\n",
    "    'gameDate', 'gameTimeUTC'])\r\n",
    "    else col_value\r\n",
    "  for col_value in team_game_stats.columns.values\r\n",
    "  ]\r\n",
    "\r\n",
    "# Merge games table with team game stats\r\n",
    "team_games_with_stats = pd.merge(\r\n",
    "  team_games,\r\n",
    "  team_game_stats.\r\n",
    "    # Drop some fields that are already present in team_games table\r\n",
    "    drop(['home', 'gameDate', 'gameTimeUTC'], axis = 1),\r\n",
    "  on = ['dailyDataDate', 'gamePk', 'teamId'],\r\n",
    "  # Doing this as 'inner' join excludes spring training games, postponed games,\r\n",
    "  # etc. from original games table, but this may be fine for purposes here \r\n",
    "  how = 'inner'\r\n",
    "  )\r\n",
    "\r\n",
    "team_date_stats_agg = (team_games_with_stats.\r\n",
    "  groupby(['dailyDataDate', 'teamId', 'gameType', 'oppId', 'oppName'], \r\n",
    "    as_index = False).\r\n",
    "  agg(\r\n",
    "    numGamesTeam = ('gamePk', 'nunique'),\r\n",
    "    winsTeam = ('teamWinner', 'sum'),\r\n",
    "    lossesTeam = ('oppWinner', 'sum'),\r\n",
    "    runsScoredTeam = ('teamScore', 'sum'),\r\n",
    "    runsAllowedTeam = ('oppScore', 'sum')\r\n",
    "    )\r\n",
    "   )\r\n",
    "\r\n",
    "# Prepare standings table for merge w/ player digital engagement data\r\n",
    "# Pick only certain fields of interest from standings for merge\r\n",
    "standings_selected_fields = (standings[['dailyDataDate', 'teamId', \r\n",
    "  'streakCode', 'divisionRank', 'leagueRank', 'wildCardRank', 'pct'\r\n",
    "  ]].\r\n",
    "  rename(columns = {'pct': 'winPct'})\r\n",
    "  )\r\n",
    "\r\n",
    "# Change column names to reflect these are all \"team\" standings - helps \r\n",
    "# to differentiate from player-related fields if/when joining later\r\n",
    "standings_selected_fields.columns = [\r\n",
    "  (col_value + 'Team') \r\n",
    "  if (col_value not in ['dailyDataDate', 'teamId'])\r\n",
    "    else col_value\r\n",
    "  for col_value in standings_selected_fields.columns.values\r\n",
    "  ]\r\n",
    "\r\n",
    "standings_selected_fields['streakLengthTeam'] = (\r\n",
    "  standings_selected_fields['streakCodeTeam'].\r\n",
    "    str.replace('W', '').\r\n",
    "    str.replace('L', '').\r\n",
    "    astype(float)\r\n",
    "    )\r\n",
    "\r\n",
    "# Add fields to separate winning and losing streak from streak code\r\n",
    "standings_selected_fields['winStreakTeam'] = np.where(\r\n",
    "  standings_selected_fields['streakCodeTeam'].str[0] == 'W',\r\n",
    "  standings_selected_fields['streakLengthTeam'],\r\n",
    "  np.nan\r\n",
    "  )\r\n",
    "\r\n",
    "standings_selected_fields['lossStreakTeam'] = np.where(\r\n",
    "  standings_selected_fields['streakCodeTeam'].str[0] == 'L',\r\n",
    "  standings_selected_fields['streakLengthTeam'],\r\n",
    "  np.nan\r\n",
    "  )\r\n",
    "\r\n",
    "standings_for_digital_engagement_merge = (pd.merge(\r\n",
    "  standings_selected_fields,\r\n",
    "  dates_with_info[['dailyDataDate', 'inSeason']],\r\n",
    "  on = ['dailyDataDate'],\r\n",
    "  how = 'left'\r\n",
    "  ).\r\n",
    "  # Limit down standings to only in season version\r\n",
    "  query(\"inSeason\").\r\n",
    "  # Drop fields no longer necessary (in derived values, etc.)\r\n",
    "  drop(['streakCodeTeam', 'streakLengthTeam', 'inSeason'], axis = 1).\r\n",
    "  reset_index(drop = True)\r\n",
    "  )\r\n",
    "\r\n",
    "#### Merge together various data frames to add date, player, roster, and team info ####\r\n",
    "# Copy over player engagement df to add various pieces to it\r\n",
    "player_engagement_with_info = nextDayPlayerEngagement.copy()\r\n",
    "\r\n",
    "# Take \"row mean\" across targets to add (helps with studying all 4 targets at once)\r\n",
    "player_engagement_with_info['targetAvg'] = np.mean(\r\n",
    "  player_engagement_with_info[['target1', 'target2', 'target3', 'target4']],\r\n",
    "  axis = 1)\r\n",
    "\r\n",
    "# Merge in date information\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  dates_with_info[['dailyDataDate', 'date', 'year', 'month', 'inSeason',\r\n",
    "    'seasonPart']],\r\n",
    "  on = ['dailyDataDate'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "\r\n",
    "# Merge in some player information\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  players[['playerId', 'playerName', 'DOB', 'mlbDebutDate', 'birthCity',\r\n",
    "    'birthStateProvince', 'birthCountry', 'primaryPositionName']],\r\n",
    "   on = ['playerId'],\r\n",
    "   how = 'left'\r\n",
    "   )\r\n",
    "\r\n",
    "# Merge in some player roster information by date\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  (rosters[['dailyDataDate', 'playerId', 'statusCode', 'status', 'teamId']].\r\n",
    "    rename(columns = {\r\n",
    "      'statusCode': 'rosterStatusCode',\r\n",
    "      'status': 'rosterStatus',\r\n",
    "      'teamId': 'rosterTeamId'\r\n",
    "      })\r\n",
    "    ),\r\n",
    "  on = ['dailyDataDate', 'playerId'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "    \r\n",
    "# Merge in team name from player's roster team\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  (teams[['id', 'teamName']].\r\n",
    "    rename(columns = {\r\n",
    "      'id': 'rosterTeamId',\r\n",
    "      'teamName': 'rosterTeamName'\r\n",
    "      })\r\n",
    "    ),\r\n",
    "  on = ['rosterTeamId'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "\r\n",
    "# Merge in some player game stats (previously aggregated) from that date\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  player_date_stats_agg,\r\n",
    "  on = ['dailyDataDate', 'playerId'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "\r\n",
    "# Merge in team name from player's game team\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  (teams[['id', 'teamName']].\r\n",
    "    rename(columns = {\r\n",
    "      'id': 'gameTeamId',\r\n",
    "      'teamName': 'gameTeamName'\r\n",
    "      })\r\n",
    "    ),\r\n",
    "  on = ['gameTeamId'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "\r\n",
    "# Merge in some team game stats/results (previously aggregated) from that date\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  team_date_stats_agg.rename(columns = {'teamId': 'gameTeamId'}),\r\n",
    "  on = ['dailyDataDate', 'gameTeamId'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "\r\n",
    "# Merge in player transactions of note on that date\r\n",
    "    \r\n",
    "# Merge in some pieces of team standings (previously filter/processed) from that date\r\n",
    "player_engagement_with_info = pd.merge(\r\n",
    "  player_engagement_with_info,\r\n",
    "  standings_for_digital_engagement_merge.\r\n",
    "    rename(columns = {'teamId': 'gameTeamId'}),\r\n",
    "  on = ['dailyDataDate', 'gameTeamId'],\r\n",
    "  how = 'left'\r\n",
    "  )\r\n",
    "\r\n",
    "display(player_engagement_with_info)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "496b04e30059469958467f0d4db1620d644ed6cb7bd63306bef423de4168438b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}